---
title: 1.5 Linear Independence
date: 2026-01-06 09:00:00 +0900
categories: [Mathematics, Linear Algebra]
tags: [math, linear algebra]
math: true
---

# 1.5 Linear Independence

## Definition
A subset $S$ of a vector space $V$ is **linearly dependent** if there exist a finite number of distinct vectors $u_1, \dots, u_n$ in $S$ and scalars $a_1, \dots, a_n$, not all zero, such that:
$$a_1 u_1 + a_2 u_2 + \dots + a_n u_n = 0$$
[cite_start][cite: 3, 4, 5, 6, 7, 8, 9, 10, 11, 13]

[cite_start]*(Note: Linear independence means the set only has the trivial representation for 0)* [cite: 14, 16]

### Example 1
[cite_start]Let $S = \{(1,3,-4,2), (2,2,-4,0), (1,-3,2,-4), (-1,0,1,0)\}$. [cite: 17]

Consider the linear combination:
$$4(1,3,-4,2) - 3(2,2,-4,0) + 2(1,-3,2,-4) + 0(-1,0,1,0) = 0$$
[cite_start]Here, the coefficients are $a_1 = 4, a_2 = -3, a_3 = 2, a_4 = 0$. [cite: 18, 19]

[cite_start]Since not all coefficients are zero, $S$ is **linearly dependent**. [cite: 20, 21]

### Example 2
Consider the set of matrices:
$$S = \left\{ \begin{bmatrix}1&-3&2\\ -4&0&5\end{bmatrix}, \begin{bmatrix}-3&7&4\\ 6&-2&-9\end{bmatrix}, \begin{bmatrix}-2&3&11\\ -1&-3&2\end{bmatrix} \right\}$$
[cite_start][cite: 23]

Observe that:
$$5\begin{bmatrix}1&-3&2\\ -4&0&5\end{bmatrix} + 3\begin{bmatrix}-3&7&4\\ 6&-2&-9\end{bmatrix} - 2\begin{bmatrix}-2&3&11\\ -1&-3&2\end{bmatrix} = \begin{bmatrix}0&0&0\\ 0&0&0\end{bmatrix}$$
[cite_start][cite: 24]

[cite_start]Therefore, the set is **linearly dependent**. [cite: 25]

---

## Remarks
(i) [cite_start]The empty set $\emptyset$ is linearly independent. [cite: 27, 28]

(ii) A set consisting of a single nonzero vector is linearly independent.
*Proof:* If $\{u\}$ is linearly dependent, then $au = 0$ for some nonzero scalar $a$.
Thus, $u = a^{-1}(au) = a^{-1} \cdot 0 = 0$. [cite_start]So, $u$ must be 0. [cite: 30, 31, 33, 34, 35, 41, 42]

(iii) [cite_start]$S$ is linearly independent if and only if the only representation of $0$ is the trivial representation. [cite: 44, 45, 46, 48]

### Example 3
[cite_start]Let $S = \{(1,0,0,-1), (0,1,0,-1), (0,0,1,-1), (0,0,0,1)\}$. [cite: 50]

Set the linear combination to zero:
$$a_1(1,0,0,-1) + a_2(0,1,0,-1) + a_3(0,0,1,-1) + a_4(0,0,0,1) = (0,0,0,0)$$
[cite_start][cite: 51]

[cite_start]Solving this system yields $a_1 = a_2 = a_3 = a_4 = 0$ as the only solution. [cite: 52, 53]
[cite_start]Therefore, $S$ is **linearly independent**. [cite: 54]

---

## Theorem 1.6
Let $V$ be a vector space and $S_1 \subseteq S_2 \subseteq V$.
[cite_start]**If $S_1$ is linearly dependent, then $S_2$ is linearly dependent.** [cite: 55]

**Proof:**
Let $S_1$ be linearly dependent.
Then $S_1$ has a nontrivial representation for $0$:
$$a_1 u_1 + \dots + a_n u_n = 0$$
where not all $a_i$ are zero.
Note that $u_i \in S_1 \subseteq S_2$.
Thus, $S_2$ has a nontrivial representation for $0$.
[cite_start]Therefore, $S_2$ is linearly dependent. [cite: 55]

## Corollary
Let $S_1 \subseteq S_2 \subseteq V$.
[cite_start]**If $S_2$ is linearly independent, then $S_1$ is linearly independent.** [cite: 55]

**Proof:**
Suppose to the contrary that $S_1$ is linearly dependent.
Then for $u_i \in S_1$, there exist $c_i$ (not all zero) such that:
$$\sum c_i u_i = 0$$
Since $S_1 \subseteq S_2$, these vectors are in $S_2$.
[cite_start]This implies $S_2$ is linearly dependent, which is a contradiction. [cite: 55]

---

## Theorem 1.7
Let $S$ be a linearly independent subset of $V$, and let $v \in V$ be a vector not in $S$.
Then, **$S \cup \{v\}$ is linearly dependent if and only if $v \in \text{span}(S)$.**
[cite_start]*(i.e., $S$ is the "smallest" generating set for its span)*. [cite: 56, 57, 60, 61, 63, 67]

**Proof:**

**$(\Rightarrow)$**
If $S \cup \{v\}$ is linearly dependent, then there exist vectors $u_1, \dots, u_n$ in $S \cup \{v\}$ such that:
$$a_1 u_1 + \dots + a_n u_n = 0$$
[cite_start]where scalars $a_1, \dots, a_n$ are not all zero. [cite: 71, 74, 76, 80, 81]

Since $S$ is linearly independent, one of the vectors, say $u_1$, must equal $v$ (otherwise the dependence is entirely within $S$, which is impossible). [cite_start]Let $a_1 \neq 0$. [cite: 82, 83, 84]
$$a_1 v + a_2 u_2 + \dots + a_n u_n = 0$$
$$v = a_1^{-1}(-a_2 u_2 - \dots - a_n u_n)$$
$$v = -(a_1^{-1}a_2)u_2 - \dots - (a_1^{-1}a_n)u_n$$
[cite_start]Thus, $v \in \text{span}(S)$. [cite: 85, 86, 88]

**$(\Leftarrow)$**
[cite_start]Let $v \in \text{span}(S)$. [cite: 90, 91]
Then $v$ can be written as a linear combination of vectors in $S$:
$$v = b_1 v_1 + \dots + b_m v_m$$
[cite_start]for $v_i \in S$. [cite: 93, 94]

Rearranging this equation gives:
$$0 = b_1 v_1 + \dots + b_m v_m - v$$
[cite_start][cite: 96]

Note that the coefficient of $v$ is $-1$ (which is nonzero).
[cite_start]Since $S \cup \{v\}$ contains $v_1, \dots, v_m, v$, this equation shows that $S \cup \{v\}$ has a nontrivial representation for $0$. [cite: 97, 102]
[cite_start]Therefore, $S \cup \{v\}$ is linearly dependent. [cite: 105]